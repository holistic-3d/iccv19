<!DOCTYPE html>
<html lang="en">
<head>
  <title>Holistic 3D Reconstruction @ ICCV 2019</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
  <link href="css/style.css" rel="stylesheet" type="text/css" />
  
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
  <style>
    /* Remove the navbar's default margin-bottom and rounded borders */ 
    .navbar {
      margin-bottom: 0;
      border-radius: 0;
    }
    
    /* Add a gray background color and some padding to the footer */
    footer {
      background-color: #f2f2f2;
      padding: 25px;
    }
  </style>
</head>
<body>

<nav class="navbar navbar-inverse navbar-fixed-top">
  <div class="container-fluid">
    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>                        
      </button>
    </div>
    
    <div class="collapse navbar-collapse" id="myNavbar">
      <ul class="nav navbar-nav">
        <li class="active"><a href="#">Home</a></li>
        <li><a href="#overview">Overview</a></li>
        <li><a href="#organizers">Organizers</a></li>
        <li><a href="#schedule">Schedule</a></li>
        <li><a href="#resources">Resources</a></li>
      </ul>
    </div>
    
  </div>
</nav>

<br>

<div class="jumbotron">
  <div class="container text-center">
    <h4>ICCV 2019 Tutorial</h4> 
    <h2>Holistic 3D Reconstruction: Learning to Reconstruct Holistic 3D Structures from Sensorial Data</h2>
    <p>Monday, October 28, 2019 - AM <br> Location: Room 300, COEX Convention Center, Seoul, Korea</p>
    <p><img src="figures/iccv19-teaser.jpg" width="800"></p>
  </div>
</div>
  
<div class="container" id="overview">
  <h2>Overview</h2>
    <p>The perception of holistic scene structures, that is, orderly, regular, symmetric, or repetitive
patterns and relationships in a scene, plays a critical role in human vision. When walking in a
man-made environment, such as office buildings, a human can instantly identify parallel lines,
rectangles, cuboids, rotational symmetries, repetitive patterns, and many other types of
structure, and exploit them for accurate and robust 3D localization, orientation, and navigation.
In computer vision, the use of such holistic structural elements has a long history in 3D
modeling of physical environments, especially man-made environments, from data acquired by
a variety of sensors such as monocular and binocular vision, LiDAR, and RGB-D sensors.
These methods have shown great success and potential in creating high-fidelity 3D models,
increasing the accuracy, robustness, and reliability of 3D vision systems, and facilitating modern
3D applications with a high-level, compact, and semantically rich scene representation.
    </p>
  <p>
    In this context, this tutorial aims at bringing together the current research advances and
discussing the state-of-the-art methods in 3D modeling of structured scenes and its
applications. The tutorial will review the fundamental theory of multiview geometry of 3D
structures; analyze traditional and recent geometric approaches in utilizing holistic 3D
structures; present an overview of current confluence of learning-based approaches and
geometry-based approaches. Finally we discuss possible future directions in combining
reconstruction and recognition for 3D modeling of man-made environments.
    </p>
</div>

<div class="container" id="organizers">
    <h2>Organizers</h2>
    <div align="center">
        
        <div class="instructor">
            <a href="https://faculty.ist.psu.edu/zzhou/">
                <div class="instructorphoto"><img src="https://faculty.ist.psu.edu/zzhou/images/zihan.jpg" id="zhou"></div>
                <div>Zihan Zhou<br>Penn State U.</div>
                
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://www.sfu.ca/computing/people/faculty/yasutakafurukawa1.html">
                <div class="instructorphoto"><img src="figures/furukawa.jpg" id="furukawa"></div>
                <div>Yasutaka Furukawa<br>Simon Fraser U.</div>
            </a>
        </div>
        
        <div class="instructor">
            <a href="https://people.eecs.berkeley.edu/~yima/">
                <div class="instructorphoto"><img src="figures/YiMa.jpg" id="ma"></div>
                <div>Yi Ma<br>UC Berkeley</div>
            </a>
        </div>
        
    </div>
</div>


<div class="container" id="schedule">
  <h2>Schedule</h2>
    <div class="schedule">
        <p><span class="announce_date">8:30 - 9:15 </span>.  <b>Theory of holistic 3D reconstruction</b> by <em>Yi Ma</em></p>
      <p><span class="announce_date">9:15 - 10:15 </span>.  <b>Learning to reconstruct 3D CAD models</b> by <em> Zihan Zhou </em> </p>
      <p><span class="announce_date">10:15 - 10:45 </span>.  Coffee break </p>
      <p><span class="announce_date">10:45 - 11:45 </span>.  <b>2D planar graph inverse CAD</b> by <em>Yasutaka Furukawa</em> and <em> Chen Liu</em> </p>
      <p><span class="announce_date">11:45 - 12:30 </span>.  <b>Current topics, open questions, datasets</b> by <em> Yasutaka Furukawa</em> and <em> Zihan Zhou </em> </p>
    </div>
</div>

<div class="container" id="resources">
    <h2>Resources</h2>
    <h4><b>Relavant Publications by the Organizers</b></h4>
    <ol>
        <li>Y. Zhou, H. Qi, and Y. Ma. NeurVPS: Neural Vanishing Point Scanning via Conic Convolution. In NeurIPS, 2019.</li>
        <li>Y. Zhou, H. Qi, and Y. Ma. End-to-End Wireframe Parsing. In ICCV, 2019.</li>
        <li>Y. Zhou, H. Qi, Y. Zhai, Q. Sun, Z. Chen, L. Wei, and Y. Ma. Learning to Reconstruct 3D Manhattan Wireframes from a Single Image. In ICCV, 2019.</li>
        <li>J. Chen, C. Liu, J. Wu, and Y. Furukawa. Floor-SP: Inverse CAD for Floorplans by Sequential Room-wise Shortest Path. In ICCV, 2019.</li>
        <li>J. Zheng*, J. Zhang*, J. Li*, R. Tang, S. Gao, and Z. Zhou. Structured3D: A Large Photo-realistic Dataset for Structured 3D Modeling. arXiv:1908.00222, 2019.</li>
        <li>C. Liu, K. Kim, J. Gu, Y. Furukawa, and J. Kautz. PlaneRCNN: 3D Plane Detection and Reconstruction from a Single Image. In CVPR, 2019.</li>
        <li>Z. Yu*, J. Zheng*, D. Lian, Z. Zhou, and S. Gao. Single-Image Piece-wise Planar 3D Reconstruction via Associative Embedding. In CVPR, 2019.</li>
        <li>Z. Zhang*, Z. Li*, N. Bi, J. Zheng, J. Wang, K. Huang, W. Luo, Y. Xu, and S. Gao. PPGNet: Learning Point-Pair Graph for Line Segment Detection. In CVPR, 2019.</li>
         <li>F. Yang and Z. Zhou. Recovering 3D planes from a single image via convolutional neural networks. In ECCV, 2018.</li>
         <li>H. Zeng, J. Wu, and Y. Furukawa. Neural Procedural Reconstruction for Residential Buildings. In ECCV, 2018.</li>
         <li>C. Liu*, J. Yu*, and Y. Furukawa. FloorNet: A Unified Framework for Floorplan Reconstruction from 3D Scans. In ECCV 2018.</li>
         <li>C. Liu, J. Yang, D. Ceylan, E. Yumer, and Y. Furukawa. PlaneNet: Piece-wise Planar Reconstruction from a Single RGB Image. In CVPR, 2018.</li>
         <li>K. Huang, Y. Wang, Z. Zhou, T. Ding, S. Gao, and Y. Ma. Learning to parse wireframes in images of man-made environments. In CVPR, 2018.</li>
         <li>C. Liu, J. Wu, P. Kohli, and Y. Furukawa. Raster-to-Vector: Revisiting Floorplan Transformation. In ICCV, 2017.</li>
         <li>E. Wijmans and Y. Furukawa. Exploiting 2D Floorplan for Building-scale Panorama RGBD Alignment. In CVPR, 2017.</li>
         <li>C. Zhu, Z. Zhou, Z. Xing, Y. Dong, Y. Ma, and J. Yu. Robust Plane-based Calibration of Multiple Non-Overlapping Cameras. In 3DV, 2016.</li>
         <li>C. Liu, P. Kohli, and Y. Furukawa. Layered Scene Decomposition via the Occlusion-CRF. In CVPR, 2016.</li>
         <li>S. Ikehata, H. Yan, and Y. Furukawa. Structured Indoor Modeling. In ICCV, 2015.</li>
         <li>R. Cabral and Y. Furukawa. Piecewise Planar and Compact Floorplan Reconstruction from Images. In CVPR 2014.</li>
         <li>Z. Zhou, H. Jin, and Y. Ma. Plane-Based Content-Preserving Warps for Video Stabilization. In CVPR, 2013.</li>
         <li>J. Xiao and Y. Furukawa. Reconstructing the World's Museums. In ECCV, 2012.</li>
         <li>Z. Zhou, H. Jin, and Y. Ma. Robust Plane-Based Structure From Motion. In CVPR, 2012.</li>
         <li>H. Mobahi, Z. Zhou, A. Y. Yang, and Y. Ma. Holistic Reconstruction of Urban Structures from Low-rank Textures. In ICCV-3dRR, 2011.</li>
         <li>Z. Zhang, X. Liang, and Y. Ma. Unwrapping Low-rank Textures on Generalized Cylindrical Surfaces. In ICCV, 2011.</li>
         <li>Z. Zhang, Y. Matsushita, and Y. Ma. Camera Calibration with Lens Distortion from Low-rank Textures. In CVPR, 2011.</li>
         <li>Y. Furukawa, B. Curless, S. M. Seitz and R. Szeliski. Reconstructing Building Interiors from Images. In ICCV, 2009.</li>
         <li>Y. Furukawa, B. Curless, S. M. Seitz, and R. Szeliski. Manhattan-world stereo. In CVPR, 2009.</li>
         <li>Y. Ma, S. Soatto, J. Kosecka, and S. S. Sastry. An Invitation to 3D Vision: From Images to Geometric Models. Springer Verlag, 2003.</li>
    </ol>
    <h4><b>Other Papers to be Covered</b></h4>
    <ol>
        <li>J. Wu, T. Xue, J. J. Lim, Y. Tian, J. B. Tenenbaum, A. Torralba, and W. T. Freeman. 3d interpreter networks for viewer centered wireframe modeling. IJCV, 2018.</li>
        <li>C. Zou, A. Colburn, Q. Shan, and D. Hoiem. Layoutnet: Reconstructing the 3d room layout from a single RGB image. In CVPR, 2018.</li>
        <li>C. Niu, J. Li, and K. Xu. Im2struct: Recovering 3d shape structure from a single RGB image. In CVPR, 2018.</li>
        <li>C. Lee, V. Badrinarayanan, T. Malisiewicz, and A. Rabinovich. Roomnet: End-to-end room layout estimation. In ICCV, 2017.</li>
        <li>S. Tulsiani, H. Su, L. J. Guibas, A. A. Efros, and J. Malik. Learning Shape Abstractions by Assembling Volumetric Primitives. In CVPR, 2017.</li>
        <li>H. Izadinia, Q. Shan, S. M. Seitz. IM2CAD. In CVPR, 2017.</li>
        <li>S. Dasgupta, K. Fang, K. Chen, and S. Savarese. Delay: Robust spatial layout estimation for cluttered indoor scenes. In CVPR, 2016.</li>
        <li>O. Haines and A. Calway. Recognising planes in a single image. IEEE TPAMI, 2015.</li>
        <li>A. Monszpart, N. Mellado, G. J. Brostow, and N. J. Mitra. RAPTER: Rebuilding Man-made Scenes with Regular Arrangements of Planes. SIGGRAPH, 2015.</li>
        <li>D. F. Fouhey, A. Gupta, and M. Hebert. Unfolding an indoor origami world. In ECCV, 2014.</li>
        <li>S. Ramalingam and M. Brand. Lifting 3D manhattan lines from a single image. In ICCV, 2013.</li>
        <li>S. Ramalingam, J. K. Pillai, A. Jain, and Y. Taguchi. Manhattan junction catalogue for spatial reasoning of indoor scenes. In CVPR, 2013.</li>
        <li>J. Xiao, B. C. Russell, and A. Torralba. Localizing 3d cuboids in single-view images. In NIPS, 2012.</li>
        <li>A. Flint, D. W. Murray, and I. Reid. Manhattan scene understanding using monocular, stereo, and 3D features. In ICCV, 2011.</li>
        <li>C. Wu, J.-M. Frahm, and M. Pollefeys. Repetition-based dense single-view reconstruction. In CVPR, 2011.</li>
        <li>A. Elqursh and A. M. Elgammal. Line-based relative pose estimation. In CVPR, 2011.</li>
        <li>D. Gallup, J.-M. Frahm, and M. Pollefeys. Piecewise Planar and Non-Planar Stereo for Urban Scene Reconstruction. In CVPR, 2010.</li>
        <li>V. Hedau, D. Hoiem, and D. A. Forsyth. Recovering the spatial layout of cluttered rooms. In ICCV, 2009.</li>
        <li>D.C. Lee, M. Hebert, and T. Kanade. Geometric Reasoning for Single Image Structure Recovery. In CVPR, 2009.</li>
        <li>M. Pauly, N. J. Mitra, J. Wallner, H. Pottmann, and L. J. Guibas. Discovering Structural Regularity in 3D Geometry. SIGGRAPH, 2008.</li>
        <li>G. Schindler, P. Krishnamurthy, R. Lublinerman, Y. Liu, and F. Dellaert. Detecting and Matching Repeated Patterns for Automatic Geo-tagging in Urban Environments. In CVPR, 2008.</li>
        <li>B. Micusik, H. Wildenauer, and J. Kosecka. Detection and matching of rectilinear structures. In CVPR, 2008.</li>
        <li>D. Hoiem, A. A. Efros, and M. Hebert. Recovering surface layout from an image. IJCV, 2007.</li>
        <li>G. Schindler, P. Krishnamurthy, and F. Dellaert. Line-Based Structure From Motion for Urban Environments. In 3DPVT, 2006</li>
        <li>J. M. Coughlan and A. L. Yuille. Manhattan world: Orientation and outlier detection by bayesian inference. Neural Computation, 2003.</li>
        <li>A. Bartoli and P. Sturm. Constrained structure and motion from multiple uncalibrated views of a piecewise planar scene. IJCV, 2003.</li>
        <li>J. Kosecka, and W. Zhang. Video Compass. In ECCV, 2002.</li>
        <li>R. I. Hartley and A. Zisserman. Multiple View Geometry in Computer Vision. Cambridge University Press, 2000.</li>
        <li>J. Malik. Interpreting line drawings of curved objects. IJCV, 1987.</li>
        <li>A. P. Witkin and J. M. Tenenbaum. On the role of structure in vision. In J. Beck, B. Hope, and A. Rosenfeld, editors, Human and Machine Vision, pages 481–543. Academic Press, 1983.</li>
        <li>K. Sugihara. Mathematical structures of line drawings of polyhedrons-toward man-machine communication by means of line drawings. IEEE TPAMI, 1982.</li>
    </ol>
</div>

<br>


<footer class="container-fluid">
    <p>Contact: <a href="mailto:zzhou@ist.psu.edu">Zihan Zhou</a></p>
</footer>

</body>
</html>

